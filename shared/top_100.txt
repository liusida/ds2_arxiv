https://arxiv.org/abs/1409.0473 	 Neural Machine Translation by Jointly Learning to Align and Translate (2015)[9998]
https://arxiv.org/abs/1608.06993 	 Densely Connected Convolutional Networks (2017)[9994]
https://arxiv.org/abs/1409.3215 	 Sequence to Sequence Learning with Neural Networks (2014)[9994]
https://arxiv.org/abs/1406.1078 	 Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation (2014)[9994]
https://arxiv.org/abs/1310.4546 	 Distributed Representations of Words and Phrases and their Compositionality (2013)[9994]
https://arxiv.org/abs/1201.0490 	 Scikit-learn: Machine Learning in Python (2011)[9993]
https://arxiv.org/abs/1502.03167 	 Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift (2015)[9993]
https://arxiv.org/abs/1106.1813 	 SMOTE: Synthetic Minority Over-sampling Technique (2002)[9993]
https://arxiv.org/abs/1408.5093 	 Caffe: Convolutional Architecture for Fast Feature Embedding (2014)[9991]
https://arxiv.org/abs/1312.6114 	 Auto-Encoding Variational Bayes (2014)[9990]
https://arxiv.org/abs/1706.03762 	 Attention Is All You Need (2017)[9988]
https://arxiv.org/abs/1412.6980 	 Adam: A Method for Stochastic Optimization (2015)[9988]
https://arxiv.org/abs/1502.01852 	 Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification (2015)[9220]
https://arxiv.org/abs/1605.08695 	 TensorFlow: A system for large-scale machine learning (2016)[9043]
https://arxiv.org/abs/1404.7828 	 Deep Learning in Neural Networks: An Overview (2015)[8767]
https://arxiv.org/abs/1603.04467 	 TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems (2016)[8131]
https://arxiv.org/abs/1511.06434 	 Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks (2016)[7505]
https://arxiv.org/abs/1603.02754 	 XGBoost: A Scalable Tree Boosting System (2016)[7288]
https://arxiv.org/abs/0711.0189 	 A Tutorial on Spectral Clustering (2007)[7268]
https://arxiv.org/abs/1206.5538 	 Representation Learning: A Review and New Perspectives (2013)[6960]
https://arxiv.org/abs/1412.6572 	 Explaining and Harnessing Adversarial Examples (2015)[6677]
https://arxiv.org/abs/1609.02907 	 Semi-Supervised Classification with Graph Convolutional Networks (2017)[6276]
https://arxiv.org/abs/1312.6199 	 Intriguing properties of neural networks (2014)[6195]
https://arxiv.org/abs/1103.0398 	 Natural Language Processing (almost) from Scratch (2011)[5871]
https://arxiv.org/abs/1405.4053 	 Distributed Representations of Sentences and Documents (2014)[5781]
https://arxiv.org/abs/1502.03044 	 Show, Attend and Tell: Neural Image Caption Generation with Visual Attention (2015)[5762]
https://arxiv.org/abs/1511.00561 	 SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation (2017)[5597]
https://arxiv.org/abs/1503.02531 	 Distilling the Knowledge in a Neural Network (2015)[5394]
https://arxiv.org/abs/1301.7363 	 Empirical Analysis of Predictive Algorithms for Collaborative Filtering (1998)[5372]
https://arxiv.org/abs/1412.3555 	 Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling (2014)[5359]
https://arxiv.org/abs/1207.0580 	 Improving neural networks by preventing co-adaptation of feature detectors (2012)[5205]
https://arxiv.org/abs/1312.5602 	 Playing Atari with Deep Reinforcement Learning (2013)[4796]
https://arxiv.org/abs/1212.5701 	 ADADELTA: An Adaptive Learning Rate Method (2012)[4580]
https://arxiv.org/abs/1607.04606 	 Enriching Word Vectors with Subword Information (2017)[4542]
https://arxiv.org/abs/1603.05027 	 Identity Mappings in Deep Residual Networks (2016)[4485]
https://arxiv.org/abs/1411.1792 	 How transferable are features in deep neural networks? (2014)[4453]
https://arxiv.org/abs/1509.02971 	 Continuous control with deep reinforcement learning (2016)[4406]
https://arxiv.org/abs/1912.01703 	 PyTorch: An Imperative Style, High-Performance Deep Learning Library (2019)[4298]
https://arxiv.org/abs/1411.1784 	 Conditional Generative Adversarial Nets (2014)[4272]
https://arxiv.org/abs/1602.04938 	 "Why Should I Trust You?": Explaining the Predictions of Any Classifier (2016)[4148]
https://arxiv.org/abs/1606.03498 	 Improved Techniques for Training GANs (2016)[4124]
https://arxiv.org/abs/1603.08155 	 Perceptual Losses for Real-Time Style Transfer and Super-Resolution (2016)[4110]
https://arxiv.org/abs/1403.6652 	 DeepWalk: Online Learning of Social Representations (2014)[4057]
https://arxiv.org/abs/1607.00653 	 node2vec: Scalable Feature Learning for Networks (2016)[4045]
https://arxiv.org/abs/1704.00028 	 Improved Training of Wasserstein GANs (2017)[4010]
https://arxiv.org/abs/1602.01783 	 Asynchronous Methods for Deep Reinforcement Learning (2016)[3846]
https://arxiv.org/abs/1206.2944 	 Practical Bayesian Optimization of Machine Learning Algorithms (2012)[3687]
https://arxiv.org/abs/1707.06347 	 Proximal Policy Optimization Algorithms (2017)[3540]
https://arxiv.org/abs/1302.6815 	 Learning Bayesian Networks: The Combination of Knowledge and Statistical Data (2004)[3458]
https://arxiv.org/abs/1609.08144 	 Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation (2016)[3386]
https://arxiv.org/abs/1609.03499 	 WaveNet: A Generative Model for Raw Audio (2016)[3352]
https://arxiv.org/abs/1312.4400 	 Network In Network (2014)[3322]
https://arxiv.org/abs/1302.4964 	 Estimating Continuous Distributions in Bayesian Classifiers (1995)[3140]
https://arxiv.org/abs/1706.06083 	 Towards Deep Learning Models Resistant to Adversarial Attacks (2018)[3071]
https://arxiv.org/abs/1211.5063 	 On the difficulty of training Recurrent Neural Networks (2013)[3038]
https://arxiv.org/abs/1505.07818 	 Domain-Adversarial Training of Neural Networks (2016)[3028]
https://arxiv.org/abs/1703.03400 	 Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks (2017)[2999]
https://arxiv.org/abs/1202.2745 	 Multi-column Deep Neural Networks for Image Classification (2012)[2966]
https://arxiv.org/abs/1506.02626 	 Learning both Weights and Connections for Efficient Neural Networks (2015)[2926]
https://arxiv.org/abs/1706.02216 	 Inductive Representation Learning on Large Graphs (2017)[2831]
https://arxiv.org/abs/1502.05477 	 Trust Region Policy Optimization (2015)[2822]
https://arxiv.org/abs/1605.07146 	 Wide Residual Networks (2016)[2821]
https://arxiv.org/abs/1506.02142 	 Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (2016)[2788]
https://arxiv.org/abs/1205.2618 	 BPR: Bayesian Personalized Ranking from Implicit Feedback (2009)[2769]
https://arxiv.org/abs/1511.07289 	 Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs) (2016)[2718]
https://arxiv.org/abs/1511.04587 	 Accurate Image Super-Resolution Using Very Deep Convolutional Networks (2016)[2696]
https://arxiv.org/abs/1412.7062 	 Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs (2015)[2696]
https://arxiv.org/abs/1710.10903 	 Graph Attention Networks (2018)[2680]
https://arxiv.org/abs/1606.09375 	 Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering (2016)[2678]
https://arxiv.org/abs/1602.07360 	 SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size (2017)[2656]
https://arxiv.org/abs/1503.03578 	 LINE: Large-scale Information Network Embedding (2015)[2630]
https://arxiv.org/abs/1412.4564 	 MatConvNet - Convolutional Neural Networks for MATLAB (2015)[2575]
https://arxiv.org/abs/1710.10196 	 Progressive Growing of GANs for Improved Quality, Stability, and Variation (2018)[2553]
https://arxiv.org/abs/2010.16061 	 Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation (2020)[2538]
https://arxiv.org/abs/1003.1141 	 From Frequency to Meaning: Vector Space Models of Semantics (2010)[2513]
https://arxiv.org/abs/1509.01626 	 Character-level Convolutional Networks for Text Classification (2015)[2501]
https://arxiv.org/abs/1301.6705 	 Probabilistic Latent Semantic Analysis (1999)[2481]
https://arxiv.org/abs/1412.6806 	 Striving for Simplicity: The All Convolutional Net (2015)[2477]
https://arxiv.org/abs/1611.03530 	 Understanding deep learning requires rethinking generalization (2017)[2475]
https://arxiv.org/abs/1706.08500 	 GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium (2017)[2442]
https://arxiv.org/abs/1503.04069 	 LSTM: A Search Space Odyssey (2017)[2440]
https://arxiv.org/abs/1509.06461 	 Deep Reinforcement Learning with Double Q-learning (2016)[2419]
https://arxiv.org/abs/1610.02391 	 Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization (2019)[2374]
https://arxiv.org/abs/1611.01578 	 Neural Architecture Search with Reinforcement Learning (2017)[2369]
https://arxiv.org/abs/1606.03657 	 InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets (2016)[2351]
https://arxiv.org/abs/1607.02533 	 Adversarial examples in the physical world (2017)[2342]
https://arxiv.org/abs/0908.0050 	 Online Learning for Matrix Factorization and Sparse Coding (2010)[2340]
https://arxiv.org/abs/1604.07379 	 Context Encoders: Feature Learning by Inpainting (2016)[2327]
https://arxiv.org/abs/1708.07747 	 Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms (2017)[2321]
https://arxiv.org/abs/1707.07012 	 Learning Transferable Architectures for Scalable Image Recognition (2018)[2316]
https://arxiv.org/abs/1606.04080 	 Matching Networks for One Shot Learning (2016)[2315]
https://arxiv.org/abs/1705.07750 	 Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset (2017)[2288]
https://arxiv.org/abs/1210.5644 	 Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials (2011)[2233]
https://arxiv.org/abs/1609.04747 	 An overview of gradient descent optimization algorithms (2016)[2230]
https://arxiv.org/abs/1211.0053 	 The Emerging Field of Signal Processing on Graphs: Extending High-Dimensional Data Analysis to Networks and Other Irregular Domains (2013)[2206]
https://arxiv.org/abs/1105.5444 	 Semantic Similarity in a Taxonomy: An Information-Based Measure and its Application to Problems of Ambiguity in Natural Language (1999)[2190]
https://arxiv.org/abs/1701.07875 	 Wasserstein GAN (2017)[2188]
https://arxiv.org/abs/1705.07874 	 A Unified Approach to Interpreting Model Predictions (2017)[2160]
https://arxiv.org/abs/1906.08237 	 XLNet: Generalized Autoregressive Pretraining for Language Understanding (2019)[2135]
https://arxiv.org/abs/1106.0257 	 Popular Ensemble Methods: An Empirical Study (1999)[2130]
